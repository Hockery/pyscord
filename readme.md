# python爬虫

## 简单说明
> 在制作爬虫的过程中, 发现大量的冗余, 如爬取数据的解析步骤和数据结果的不同种类的安全性检查等. 减少这些冗余既可以加强爬虫的通用性还可以增加爬虫的健壮性. 这有点像是一个爬虫框架做的事情, 而且目前很多强大的爬虫框架, 但是我感觉他们让使用者做了不少事情, 我内心是像做一个简单的东西, 做多了多少有些抵触.

> 以后的话就是吧这个格式用界面实现json配置的编写, 更加人性化. 简单易用.

## 功能描述
> 爬虫的目的是爬取网页上的数据, 可以分为三个步骤, 网页的获取, 网页的解析, 结果的存储.
>> 1. 网页的获取, 主要是爬取的嵌套处理和应对反爬虫机制, 由于反爬虫机制一般要对各网站都有自己的一套, 博大精深, 目前只做了简单的规划, 以后在慢慢探讨.
>> 2. 网页的解析, 一般是html解析和Javascrip解析, 虽然现在有很多开源的JavaScript引擎, 但是做一个通用的javascrip爬虫解析有一定难度, 可以作为二期规划. 现在也是一切从简, 本项目目前只针对html文本部分.
>> 3. 结果存储, 对于爬取到的结果, 需要进行相应处理, 存储便是一个重要的处理方式, 最简单的就是txt存储, 还有各种类型的数据库, csv文本, json文本, xml文本等存储方式, 最近帮着一个小伙伴解决存储接口的问题, 顺着对redis进行了些了解, 这些存储方式也是博大精深. 嘿嘿, 一切从简, 先解决txt的存储.

## 项目思路
> 将爬取的步骤和思路格式化, 再用程序去解析这个格式. 我采用的格式是json, 尽量简单的表达你想做什么, 然后就让机器去完成你想做的但是很枯燥的事情.

> 总体框架就是,你想爬取的地址, 爬什么, 怎么爬, 怎么处理爬取结果.
